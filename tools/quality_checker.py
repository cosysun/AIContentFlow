#!/usr/bin/env python3
"""
AIContentFlow æ–‡ç« è´¨æ£€è„šæœ¬
è‡ªåŠ¨æ£€æŸ¥æ–‡ç« è´¨é‡å¹¶ç”Ÿæˆè´¨æ£€æŠ¥å‘Š
"""

import re
import sys
from typing import Dict, List, Tuple
from pathlib import Path


class QualityChecker:
    """æ–‡ç« è´¨æ£€å™¨"""
    
    def __init__(self, article_path: str):
        self.article_path = article_path
        with open(article_path, 'r', encoding='utf-8') as f:
            self.content = f.read()
        
        self.word_count = len(self.content)
    
    def check_all(self) -> Dict:
        """æ‰§è¡Œå…¨éƒ¨è´¨æ£€"""
        print("\nğŸ” å¼€å§‹å…¨æ–¹ä½è´¨æ£€...\n")
        
        results = {
            'tech_accuracy': self.check_tech_accuracy(),
            'logic': self.check_logic(),
            'completeness': self.check_completeness(),
            'code_quality': self.check_code_quality(),
            'readability': self.check_readability(),
            'practicality': self.check_practicality(),
            'format': self.check_format(),
            'no_ai_style': self.check_ai_style(),
            'seo': self.check_seo(),
            'innovation': self.check_innovation()
        }
        
        # è®¡ç®—æ€»åˆ†
        weights = {
            'tech_accuracy': 0.15,
            'logic': 0.10,
            'completeness': 0.10,
            'code_quality': 0.10,
            'readability': 0.10,
            'practicality': 0.10,
            'format': 0.10,
            'no_ai_style': 0.10,
            'seo': 0.10,
            'innovation': 0.05
        }
        
        total = sum(results[k] * weights[k] for k in results)
        results['total_score'] = round(total, 1)
        results['grade'] = self.get_grade(total)
        
        return results
    
    def check_tech_accuracy(self) -> float:
        """æ£€æŸ¥æŠ€æœ¯å‡†ç¡®æ€§"""
        print("ğŸ“Š æ£€æŸ¥æŠ€æœ¯å‡†ç¡®æ€§...")
        score = 10.0
        issues = []
        
        # æ£€æŸ¥æœªæ ‡æ³¨æ¥æºçš„æ•°æ®
        numbers = re.findall(r'\d+[KkMm]?\+?\s*(?:Stars?|Forks?|ä¸‹è½½|ç”¨æˆ·)', self.content)
        citations = len(re.findall(r'\[.*?\]\(.*?\)', self.content))
        
        if len(numbers) > citations + 2:
            score -= 1
            issues.append(f"å‘ç°{len(numbers)}ä¸ªæ•°æ®ç‚¹ï¼Œä½†åªæœ‰{citations}ä¸ªå¼•ç”¨é“¾æ¥")
        
        # æ£€æŸ¥ä»£ç å—ä¸­çš„å¸¸è§é”™è¯¯
        code_blocks = re.findall(r'```(?:\w+)?\n(.*?)```', self.content, re.DOTALL)
        for i, code in enumerate(code_blocks):
            if 'import' in code and 'from' not in code and code.count('import') == 1:
                if not re.search(r'^\s*import\s+\w+', code, re.MULTILINE):
                    issues.append(f"ä»£ç å—{i+1}å¯èƒ½ç¼ºå°‘importè¯­å¥")
        
        if issues:
            print(f"  âš ï¸  å‘ç° {len(issues)} ä¸ªé—®é¢˜")
            for issue in issues:
                print(f"     - {issue}")
        else:
            print("  âœ… æœªå‘ç°æ˜æ˜¾é—®é¢˜")
        
        return max(0, score)
    
    def check_logic(self) -> float:
        """æ£€æŸ¥é€»è¾‘è¿è´¯æ€§"""
        print("ğŸ”— æ£€æŸ¥é€»è¾‘è¿è´¯æ€§...")
        score = 10.0
        issues = []
        
        # æ£€æŸ¥æ ‡é¢˜å±‚çº§
        h1_count = len(re.findall(r'^# [^#]', self.content, re.MULTILINE))
        h2_count = len(re.findall(r'^## [^#]', self.content, re.MULTILINE))
        h3_count = len(re.findall(r'^### [^#]', self.content, re.MULTILINE))
        
        if h1_count != 1:
            score -= 1
            issues.append(f"H1æ ‡é¢˜åº”æœ‰ä¸”ä»…æœ‰1ä¸ªï¼Œå½“å‰{h1_count}ä¸ª")
        
        if h2_count < 3:
            score -= 0.5
            issues.append(f"H2æ ‡é¢˜è¿‡å°‘ï¼ˆ{h2_count}ä¸ªï¼‰ï¼Œå»ºè®®â‰¥3ä¸ª")
        
        # æ£€æŸ¥æ®µè½çªå…€è·³è·ƒï¼ˆç®€å•å¯å‘å¼ï¼šè¿ç»­çŸ­æ®µè½ï¼‰
        paragraphs = self.content.split('\n\n')
        short_paras = [p for p in paragraphs if 0 < len(p.strip()) < 50 and not p.strip().startswith('#')]
        if len(short_paras) > len(paragraphs) * 0.3:
            score -= 0.5
            issues.append("çŸ­æ®µè½è¿‡å¤šï¼Œå¯èƒ½å­˜åœ¨å†…å®¹è·³è·ƒ")
        
        if issues:
            print(f"  âš ï¸  å‘ç° {len(issues)} ä¸ªé—®é¢˜")
            for issue in issues:
                print(f"     - {issue}")
        else:
            print(f"  âœ… ç»“æ„åˆç†ï¼ˆH1:{h1_count}, H2:{h2_count}, H3:{h3_count}ï¼‰")
        
        return max(0, score)
    
    def check_completeness(self) -> float:
        """æ£€æŸ¥å†…å®¹å®Œæ•´æ€§"""
        print("ğŸ“ æ£€æŸ¥å†…å®¹å®Œæ•´æ€§...")
        score = 10.0
        issues = []
        
        # æ£€æŸ¥å­—æ•°
        if self.word_count < 2000:
            score -= 3
            issues.append(f"å­—æ•°ä¸è¶³ï¼ˆ{self.word_count}å­— < 2000å­—ï¼‰")
        elif self.word_count < 3000:
            score -= 1
            issues.append(f"å­—æ•°åå°‘ï¼ˆ{self.word_count}å­— < 3000å­—ï¼‰")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ç¤ºä¾‹/æ¡ˆä¾‹
        case_keywords = ['ä¾‹å¦‚', 'ç¤ºä¾‹', 'æ¡ˆä¾‹', 'Example', 'example', 'Case']
        case_count = sum(self.content.count(kw) for kw in case_keywords)
        if case_count < 3:
            score -= 1
            issues.append(f"æ¡ˆä¾‹/ç¤ºä¾‹ä¸è¶³ï¼ˆ{case_count}ä¸ª < 3ä¸ªï¼‰")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ€»ç»“
        if not re.search(r'##?\s*(?:æ€»ç»“|å°ç»“|ç»“è®º|Conclusion)', self.content, re.IGNORECASE):
            score -= 0.5
            issues.append("å»ºè®®å¢åŠ æ€»ç»“ç« èŠ‚")
        
        if issues:
            print(f"  âš ï¸  å‘ç° {len(issues)} ä¸ªé—®é¢˜")
            for issue in issues:
                print(f"     - {issue}")
        else:
            print(f"  âœ… å†…å®¹å®Œæ•´ï¼ˆ{self.word_count}å­—ï¼Œ{case_count}ä¸ªæ¡ˆä¾‹ï¼‰")
        
        return max(0, score)
    
    def check_code_quality(self) -> float:
        """æ£€æŸ¥ä»£ç è´¨é‡"""
        print("ğŸ’» æ£€æŸ¥ä»£ç è´¨é‡...")
        score = 10.0
        issues = []
        
        # æ£€æŸ¥ä»£ç å—æ ‡æ³¨
        code_blocks_with_lang = re.findall(r'```(\w+)', self.content)
        code_blocks_no_lang = re.findall(r'```\n', self.content)
        
        no_lang_count = len(code_blocks_no_lang)
        if no_lang_count > 0:
            score -= no_lang_count * 0.5
            issues.append(f"{no_lang_count}ä¸ªä»£ç å—æœªæ ‡æ³¨è¯­è¨€")
        
        # æ£€æŸ¥Pythonä»£ç è§„èŒƒï¼ˆå¦‚æœæœ‰Pythonä»£ç ï¼‰
        python_blocks = [block for block in re.findall(r'```python\n(.*?)```', self.content, re.DOTALL)]
        for i, code in enumerate(python_blocks):
            # æ£€æŸ¥ç¼©è¿›ä¸€è‡´æ€§ï¼ˆç®€å•æ£€æŸ¥ï¼‰
            if '\t' in code:
                score -= 0.5
                issues.append(f"Pythonä»£ç å—{i+1}ä½¿ç”¨Tabç¼©è¿›ï¼Œå»ºè®®ç”¨ç©ºæ ¼")
        
        total_blocks = len(code_blocks_with_lang) + no_lang_count
        if total_blocks == 0:
            print("  â„¹ï¸  æ— ä»£ç å—ï¼ˆéç¼–ç¨‹ç±»æ–‡ç« å¯å¿½ç•¥ï¼‰")
        elif issues:
            print(f"  âš ï¸  å‘ç° {len(issues)} ä¸ªé—®é¢˜")
            for issue in issues:
                print(f"     - {issue}")
        else:
            print(f"  âœ… ä»£ç è§„èŒƒï¼ˆ{total_blocks}ä¸ªä»£ç å—ï¼‰")
        
        return max(0, score)
    
    def check_readability(self) -> float:
        """æ£€æŸ¥å¯è¯»æ€§"""
        print("ğŸ‘€ æ£€æŸ¥å¯è¯»æ€§...")
        score = 10.0
        issues = []
        
        # æ£€æŸ¥è¶…é•¿æ®µè½
        paragraphs = [p for p in self.content.split('\n\n') if p.strip() and not p.strip().startswith('#')]
        long_paras = [p for p in paragraphs if p.count('\n') > 8]
        
        if len(long_paras) > 0:
            score -= len(long_paras) * 0.5
            issues.append(f"{len(long_paras)}ä¸ªè¶…é•¿æ®µè½ï¼ˆ>8è¡Œï¼‰")
        
        # æ£€æŸ¥æœ¯è¯­æ˜¯å¦æœ‰è§£é‡Šï¼ˆå¯å‘å¼ï¼šä¸“ä¸šè¯æ±‡åæ˜¯å¦æœ‰æ‹¬å·/å†’å·è¯´æ˜ï¼‰
        # ç®€åŒ–å®ç°ï¼šæ£€æŸ¥æ˜¯å¦æœ‰é€‚å½“çš„è§£é‡Šæ€§æ–‡æœ¬
        explanation_markers = self.content.count('ï¼ˆ') + self.content.count('ï¼šå³') + self.content.count('ï¼ŒæŒ‡')
        if explanation_markers < 5:
            score -= 0.5
            issues.append("ä¸“ä¸šæœ¯è¯­è§£é‡Šè¾ƒå°‘ï¼Œå»ºè®®å¢åŠ ")
        
        # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨ç±»æ¯”
        analogy_keywords = ['å°±åƒ', 'ç±»ä¼¼', 'å¥½æ¯”', 'ç›¸å½“äº', 'like', 'similar to']
        analogy_count = sum(self.content.count(kw) for kw in analogy_keywords)
        if analogy_count == 0:
            score -= 0.5
            issues.append("å»ºè®®ä½¿ç”¨ç±»æ¯”å¢å¼ºå¯è¯»æ€§")
        
        if issues:
            print(f"  âš ï¸  å‘ç° {len(issues)} ä¸ªé—®é¢˜")
            for issue in issues:
                print(f"     - {issue}")
        else:
            print(f"  âœ… å¯è¯»æ€§è‰¯å¥½")
        
        return max(0, score)
    
    def check_practicality(self) -> float:
        """æ£€æŸ¥å®ç”¨æ€§"""
        print("ğŸ› ï¸  æ£€æŸ¥å®ç”¨æ€§...")
        score = 10.0
        issues = []
        
        # æ£€æŸ¥å¤–éƒ¨é“¾æ¥
        links = re.findall(r'\[.*?\]\((https?://.*?)\)', self.content)
        if len(links) < 3:
            score -= 1
            issues.append(f"å¤–éƒ¨é“¾æ¥è¾ƒå°‘ï¼ˆ{len(links)}ä¸ª < 3ä¸ªï¼‰")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å®æˆ˜æ¡ˆä¾‹ï¼ˆå®Œæ•´çš„é¡¹ç›®/ä»£ç ä»“åº“ï¼‰
        github_links = [l for l in links if 'github.com' in l]
        if len(github_links) == 0:
            score -= 0.5
            issues.append("å»ºè®®æä¾›GitHubç¤ºä¾‹ä»£ç ")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ­¥éª¤æ¸…å•/é…ç½®è¯´æ˜
        if '```' not in self.content:
            score -= 1
            issues.append("ç¼ºå°‘ä»£ç /é…ç½®ç¤ºä¾‹")
        
        if issues:
            print(f"  âš ï¸  å‘ç° {len(issues)} ä¸ªé—®é¢˜")
            for issue in issues:
                print(f"     - {issue}")
        else:
            print(f"  âœ… å®ç”¨æ€§å¼ºï¼ˆ{len(links)}ä¸ªé“¾æ¥ï¼‰")
        
        return max(0, score)
    
    def check_format(self) -> float:
        """æ£€æŸ¥æ ¼å¼è§„èŒƒ"""
        print("ğŸ“ æ£€æŸ¥æ ¼å¼è§„èŒƒ...")
        score = 10.0
        issues = []
        
        # æ£€æŸ¥ä¸­è‹±æ–‡é—´è·ï¼ˆç®€å•å¯å‘å¼ï¼‰
        no_space_matches = re.findall(r'[\u4e00-\u9fa5][a-zA-Z]|[a-zA-Z][\u4e00-\u9fa5]', self.content)
        if len(no_space_matches) > 20:
            score -= 1
            issues.append(f"ä¸­è‹±æ–‡é—´è·é—®é¢˜è¾ƒå¤šï¼ˆ{len(no_space_matches)}å¤„ï¼‰")
        
        # æ£€æŸ¥æ ‡ç‚¹ç¬¦å·ï¼ˆä¸­è‹±æ–‡æ··ç”¨ï¼‰
        chinese_comma_in_english = re.findall(r'[a-zA-Z]ï¼Œ', self.content)
        english_comma_in_chinese = re.findall(r'[\u4e00-\u9fa5],(?![0-9])', self.content)
        
        if len(chinese_comma_in_english) + len(english_comma_in_chinese) > 5:
            score -= 0.5
            issues.append("æ ‡ç‚¹ç¬¦å·ä¸­è‹±æ–‡æ··ç”¨")
        
        # æ£€æŸ¥è¡¨æ ¼å¯¹é½ï¼ˆMarkdownè¡¨æ ¼ï¼‰
        tables = re.findall(r'\|.*\|', self.content)
        if len(tables) > 0:
            # ç®€å•æ£€æŸ¥ï¼šè¡¨æ ¼æ˜¯å¦æœ‰åˆ†éš”è¡Œ
            table_separators = re.findall(r'\|[\s:-]+\|', self.content)
            if len(table_separators) < len(tables) * 0.3:
                score -= 0.5
                issues.append("è¡¨æ ¼æ ¼å¼å¯èƒ½ä¸è§„èŒƒ")
        
        if issues:
            print(f"  âš ï¸  å‘ç° {len(issues)} ä¸ªé—®é¢˜")
            for issue in issues:
                print(f"     - {issue}")
        else:
            print(f"  âœ… æ ¼å¼è§„èŒƒ")
        
        return max(0, score)
    
    def check_ai_style(self) -> float:
        """æ£€æŸ¥AIè…”"""
        print("ğŸ¨ æ£€æŸ¥AIè…”...")
        score = 10.0
        issues = []
        
        # æ£€æµ‹å¥—è¯
        cliches = {
            'åœ¨å½“ä»Š': 1,
            'éšç€': 1,
            'å€¼å¾—æ³¨æ„çš„æ˜¯': 0.5,
            'éœ€è¦æŒ‡å‡ºçš„æ˜¯': 0.5,
            'æ¯«æ— ç–‘é—®': 0.5,
            'æ˜¾è€Œæ˜“è§': 0.5,
            'ä¼—æ‰€å‘¨çŸ¥': 0.5,
            'ç»¼ä¸Šæ‰€è¿°': 0.5,
            'æ€»è€Œè¨€ä¹‹': 0.5
        }
        
        found_cliches = {}
        for cliche, penalty in cliches.items():
            count = self.content.count(cliche)
            if count > 0:
                score -= count * penalty
                found_cliches[cliche] = count
        
        if found_cliches:
            issues.append("å‘ç°AIå¥—è¯ï¼š" + ", ".join([f"{k}Ã—{v}" for k, v in found_cliches.items()]))
        
        # æ£€æŸ¥è¿‡æ¸¡è¯å¯†åº¦
        transition_words = ['ç„¶è€Œ', 'æ­¤å¤–', 'å› æ­¤', 'å¦å¤–', 'åŒæ—¶']
        transition_count = sum(self.content.count(w) for w in transition_words)
        transition_density = transition_count / (self.word_count / 1000)  # æ¯åƒå­—
        
        if transition_density > 8:
            score -= 1
            issues.append(f"è¿‡æ¸¡è¯å¯†åº¦è¿‡é«˜ï¼ˆ{transition_density:.1f}æ¬¡/åƒå­— > 8ï¼‰")
        
        if issues:
            print(f"  âš ï¸  å‘ç° {len(issues)} ä¸ªé—®é¢˜")
            for issue in issues:
                print(f"     - {issue}")
        else:
            print(f"  âœ… è¯­è¨€è‡ªç„¶")
        
        return max(0, score)
    
    def check_seo(self) -> float:
        """æ£€æŸ¥SEOä¼˜åŒ–"""
        print("ğŸ” æ£€æŸ¥SEOä¼˜åŒ–...")
        score = 10.0
        issues = []
        
        # è·å–æ ‡é¢˜
        h1_match = re.search(r'^# (.+)$', self.content, re.MULTILINE)
        if not h1_match:
            score -= 2
            issues.append("ç¼ºå°‘H1æ ‡é¢˜")
            return max(0, score)
        
        title = h1_match.group(1)
        
        # æ£€æŸ¥H2æ•°é‡
        h2_count = len(re.findall(r'^## [^#]', self.content, re.MULTILINE))
        if h2_count < 3:
            score -= 1
            issues.append(f"H2æ ‡é¢˜è¿‡å°‘ï¼ˆ{h2_count}ä¸ª < 3ä¸ªï¼‰")
        elif h2_count > 10:
            score -= 0.5
            issues.append(f"H2æ ‡é¢˜è¿‡å¤šï¼ˆ{h2_count}ä¸ª > 10ä¸ªï¼‰")
        
        # æ£€æŸ¥Metaä¿¡æ¯ï¼ˆå­—æ•°ç»Ÿè®¡ã€æ ‡ç­¾ç­‰ï¼‰
        has_meta = bool(re.search(r'(?:å­—æ•°|é˜…è¯»æ—¶é•¿|æ ‡ç­¾|Tags)', self.content, re.IGNORECASE))
        if not has_meta:
            score -= 1
            issues.append("å»ºè®®æ·»åŠ Metaä¿¡æ¯ï¼ˆå­—æ•°ã€é˜…è¯»æ—¶é•¿ã€æ ‡ç­¾ï¼‰")
        
        if issues:
            print(f"  âš ï¸  å‘ç° {len(issues)} ä¸ªé—®é¢˜")
            for issue in issues:
                print(f"     - {issue}")
        else:
            print(f"  âœ… SEOå‹å¥½ï¼ˆ{h2_count}ä¸ªH2ï¼‰")
        
        return max(0, score)
    
    def check_innovation(self) -> float:
        """æ£€æŸ¥åˆ›æ–°æ€§ï¼ˆä¸»è§‚è¯„åˆ†ï¼Œé»˜è®¤7åˆ†ï¼‰"""
        print("ğŸ’¡ æ£€æŸ¥åˆ›æ–°æ€§...")
        score = 7.0
        
        # ç®€å•å¯å‘å¼ï¼šæ£€æŸ¥æ˜¯å¦æœ‰ç‹¬ç‰¹è§†è§’çš„æ ‡å¿—
        innovation_markers = [
            'é¦–æ¬¡', 'é¦–ä¸ª', 'åˆ›æ–°', 'ç‹¬ç‰¹', 'æ–°æ–¹æ³•', 'æ–°æ€è·¯',
            'novel', 'innovative', 'unique', 'new approach'
        ]
        
        innovation_count = sum(self.content.lower().count(marker.lower()) for marker in innovation_markers)
        
        if innovation_count >= 3:
            score = 9.0
            print(f"  âœ… åˆ›æ–°æ€§è¾ƒå¼ºï¼ˆ{innovation_count}ä¸ªåˆ›æ–°æ ‡è®°ï¼‰")
        elif innovation_count >= 1:
            score = 8.0
            print(f"  âœ… æœ‰åˆ›æ–°ç‚¹ï¼ˆ{innovation_count}ä¸ªåˆ›æ–°æ ‡è®°ï¼‰")
        else:
            print(f"  â„¹ï¸  åˆ›æ–°æ€§ä¸€èˆ¬ï¼ˆå¯é€šè¿‡ç‹¬ç‰¹è§†è§’/æ–°æ¡ˆä¾‹æå‡ï¼‰")
        
        return score
    
    def get_grade(self, score: float) -> str:
        """è·å–è¯„çº§"""
        if score >= 90:
            return "Açº§ï¼ˆå¯å‘å¸ƒï¼‰â­â­â­â­â­"
        elif score >= 80:
            return "Bçº§ï¼ˆéœ€ä¼˜åŒ–ï¼‰â­â­â­â­"
        elif score >= 70:
            return "Cçº§ï¼ˆéœ€é‡å†™ï¼‰â­â­â­"
        else:
            return "Dçº§ï¼ˆä¸åˆæ ¼ï¼‰â­â­"
    
    def get_stars(self, score: float) -> str:
        """è·å–æ˜Ÿçº§"""
        if score >= 9:
            return "â­â­â­â­â­"
        elif score >= 8:
            return "â­â­â­â­"
        elif score >= 7:
            return "â­â­â­"
        elif score >= 6:
            return "â­â­"
        else:
            return "â­"


def main():
    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ–¹æ³•: python3 quality_checker.py <æ–‡ç« è·¯å¾„>")
        sys.exit(1)
    
    article_path = sys.argv[1]
    
    if not Path(article_path).exists():
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {article_path}")
        sys.exit(1)
    
    print(f"\nğŸ“‹ å¼€å§‹è´¨æ£€æ–‡ç« : {article_path}\n")
    print("=" * 60)
    
    checker = QualityChecker(article_path)
    results = checker.check_all()
    
    print("\n" + "=" * 60)
    print("\nğŸ“Š è´¨æ£€ç»“æœæ±‡æ€»\n")
    print(f"æ€»åˆ†ï¼š{results['total_score']}/100")
    print(f"è¯„çº§ï¼š{results['grade']}")
    print(f"\nå„ç»´åº¦å¾—åˆ†ï¼š")
    
    dimension_names = {
        'tech_accuracy': 'æŠ€æœ¯å‡†ç¡®æ€§',
        'logic': 'é€»è¾‘è¿è´¯æ€§',
        'completeness': 'å†…å®¹å®Œæ•´æ€§',
        'code_quality': 'ä»£ç è´¨é‡',
        'readability': 'å¯è¯»æ€§',
        'practicality': 'å®ç”¨æ€§',
        'format': 'æ ¼å¼è§„èŒƒ',
        'no_ai_style': 'é™AIå‘³',
        'seo': 'SEOä¼˜åŒ–',
        'innovation': 'åˆ›æ–°æ€§'
    }
    
    for key, name in dimension_names.items():
        score = results[key]
        stars = checker.get_stars(score)
        print(f"  {name:12s}: {score:4.1f}/10 {stars}")
    
    print("\n" + "=" * 60)
    
    # ç»™å‡ºå»ºè®®
    if results['total_score'] >= 90:
        print("\nğŸ‰ æ­å–œï¼æ–‡ç« è´¨é‡ä¼˜ç§€ï¼Œå¯ä»¥å‘å¸ƒï¼")
    elif results['total_score'] >= 80:
        print("\nâš ï¸  æ–‡ç« è´¨é‡è‰¯å¥½ï¼Œå»ºè®®ä¼˜åŒ–åå‘å¸ƒã€‚")
    elif results['total_score'] >= 70:
        print("\nâŒ æ–‡ç« éœ€è¦é‡å†™éƒ¨åˆ†å†…å®¹æ‰èƒ½å‘å¸ƒã€‚")
    else:
        print("\nğŸš« æ–‡ç« è´¨é‡ä¸åˆæ ¼ï¼Œä¸å»ºè®®å‘å¸ƒã€‚")
    
    print()


if __name__ == '__main__':
    main()
